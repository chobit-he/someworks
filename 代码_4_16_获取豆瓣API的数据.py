# -*- coding: utf-8 -*-import urllib.request, json, xml.dom.minidom, refrom 代码_3_4_Python获取RSS格式的数据_增加深度 import deepprocess # 导入方法def open_url(urls):	# req = urllib.request.Request(urls, data = None, headers = acc_headers)	req = urllib.request.Request(urls)# 该程序可以不使用access_token	html = urllib.request.urlopen(req)	return htmldef getreviews(bids, uids):	url = '%s/%s/reviews' % (p_url, uids)	html = open_url(url)	DOMTree = xml.dom.minidom.parseString(html.read().decode('utf-8'))	feed = DOMTree.getElementsByTagName( "feed" )[0]	rbook = feed.getElementsByTagName( "opensearch:totalResults" )[0].childNodes[0].nodeValue	m = 1	while int(rbook) > 50 * (m-1):		url = '%s/%s/reviews?max-results=50&start-index=%d' % (p_url, uids, 50 * (m-1) + 1)		m += 1		html = open_url(url)		DOMTree = xml.dom.minidom.parseString(html.read().decode('utf-8'))		feed = DOMTree.getElementsByTagName( "feed" )[0]		entry = feed.getElementsByTagName( "entry" )		for i in entry:			subject = i.getElementsByTagName( "db:subject" )[0]			lbid = subject.getElementsByTagName( "id" )[0].childNodes[0].nodeValue			if lbid.startswith('http://api.douban.com/book/subject/'):				bid = lbid[35:]				result_list.append([bids, uids, bid, deep_int])def mainprocess(bids):	url = '%s/%s/reviews' % (base_url, bids)	html = open_url(url)	html = json.loads(html.read().decode('utf-8'))	reviews_num = html['total']	n = 1	while reviews_num > 100 * (n-1):		url = '%s/%s/reviews?count=100&start=%d' % (base_url, bids, 100 * (n-1))		html = open_url(url)		html = json.loads(html.read().decode('utf-8'))		for i in html['reviews']:			a = i['author']			getreviews(bids, a['uid'])		n += 1acc_headers = {'Authorization': 'Bearer a14afef0f66fcffce3e0fcd2e34f6ff4'}base_url = 'https://api.douban.com/v2/book'p_url = 'https://api.douban.com/people'deep_int = 0result_list = []deepprocess('4718495', 1)print(result_list)